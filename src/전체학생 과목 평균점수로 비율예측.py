import pandas as pd
import numpy as np
import matplotlib.pyplot as plt #시각화
from pandas.core.indexes.base import Index
from scipy.sparse import data
from sklearn.model_selection import train_test_split #훈련
from sklearn.preprocessing import StandardScaler #모델표준화
from sklearn.neighbors import KNeighborsRegressor #분석구축

df = pd.read_csv('./data/2. 15-19년전체집계.csv', usecols=[0,1,4,5,7,9,10])
df.head(227) #[227 rows x 7 columns]
df.info()

is_2019 = df['연도'] == 2019
year2019 = df[is_2019]
Index(year2019['A과목'])
Index(year2019['B과목'])
Index(year2019['C과목'])
Index(year2019['D과목'])
Index(year2019['E과목'])
Index(year2019['학과'])


# A_length=np.array([3.029, 2.983,  2.83, 3.136, 3.023, 2.773, 2.955, 3.429, 3.273,
#               2.945, 2.821, 3.452, 3.024, 3.625, 2.871, 3.342, 3.111, 2.711,
#               2.973, 3.081, 2.862, 3.306, 3.206, 3.153, 2.851, 3.109, 2.857,
#               2.607, 3.043, 3.873, 3.226, 3.385,  3.08, 3.738, 3.057, 3.417,
#               3.725, 2.838, 3.717, 3.828, 3.851, 3.611, 2.896, 3.732, 2.914,
#                5.12, 3.063, 3.333, 3.525, 3.236])

# B_length=np.array ([4.514, 4.904, 4.544, 4.265, 4.322, 4.373, 4.606, 5.286, 5.208,
#               4.534, 4.308, 4.984,  4.69, 5.222, 4.935, 4.901,  4.54, 4.289,
#                4.72, 4.463, 4.914, 4.594, 4.302, 5.644, 4.881, 4.745, 4.196,
#               5.071, 5.362, 5.327, 5.774, 5.077,  5.32, 5.033, 4.245, 4.933,
#               5.431, 4.784, 5.067, 5.345, 4.909, 4.861, 4.708, 4.829, 4.655,
#                5.04, 4.683,  4.87,   4.5, 4.319])

# C_length=np.array ([3.914, 3.572,  3.66, 3.701, 3.701, 3.627, 3.864, 3.955, 4.481,
#               3.521, 3.308, 3.694, 4.238, 3.722,   4.0, 4.063, 3.492, 3.145,
#               3.413, 3.544, 3.672, 3.556, 3.778, 4.017, 4.224, 3.836, 3.875,
#               3.857, 4.362, 4.127, 4.792, 3.769,  4.72,  4.23,  3.66, 4.383,
#                4.02, 3.486, 4.233, 4.621, 4.099, 3.806,  4.25, 4.317, 4.086,
#                5.48,  3.54, 4.222, 3.525, 3.319])

# D_length=np.array ([  3.4, 3.489, 3.993, 3.476,  3.23,  3.56, 3.439, 3.911,  3.87,
#               3.192, 3.103, 4.065, 3.548, 3.875, 3.677, 4.153, 3.762, 3.118,
#                3.12, 3.397, 2.828, 3.481, 3.603, 4.814, 4.433, 3.491, 4.089,
#               4.571, 4.596,   4.2, 4.755, 4.288,   4.0, 4.459, 3.283, 3.983,
#               4.863, 3.865, 4.983, 4.276,  4.57, 4.444, 4.333, 4.122, 4.172,
#                 5.8, 3.841, 4.037, 4.375, 3.681])

# E_length=np.array ([3.729,  3.59, 3.741,  3.83, 3.747,  3.72, 3.636, 4.054, 4.104,
#               3.562, 3.538, 4.065, 3.881, 4.375, 3.968,  3.82, 3.778, 3.395,
#               3.533, 3.529, 3.172, 3.781, 3.762,  4.39, 3.881, 2.727, 4.071,
#               4.107, 4.085, 4.127, 4.453, 3.731,  4.12,  4.18, 3.396,   4.4,
#               4.255, 4.324, 4.767, 3.759, 4.198, 3.861, 4.333, 3.854, 3.776,
#                5.04, 4.016, 4.222,  3.65, 3.681])                    



# print(sum(A_length/50)) #3.2309    전체학과 A 과목 평균
# print(sum(B_length/50)) #4.8205    전체학과 B 과목 평균
# print(sum(C_length/50)) #3.9295    전체학과 C 과목 평균
# print(sum(D_length/50)) #3.9522    전체학과 D 과목 평균
# print(sum(E_length/50)) #3.9142    전체학과 D 과목 평균

# ALL_length=np.array([(sum(A_length/50)),(sum(B_length/50)),(sum(C_length/50)),(sum(D_length/50)),(sum(E_length/50))])
ALL_length = np.array([3.23092, 4.82054, 3.92954, 3.95228, 3.91428])
#array([3.23092, 4.82054, 3.92954, 3.95228, 3.91428])


weight=np.array(['건축설비소방과', '건축학부', '경영학부', '글로벌외식조리학부', '기계과', '디지털전자과', '메카트로닉스과',
       '방송음향영상학부', '비서사무행정과', '사회복지과', '스포츠지도과', '아동문헌정보과', '언어재활과', '유아교육과',
       '의공융합과', '자동차학부', '자동화시스템과', '전기과', '전자통신과', '컴퓨터정보학부', '토목환경과',
       '항공호텔관광학부', '건축과', '건축설비소방과', '경영과', '기계과', '디지털전자과', '메카트로닉스과',
       '모바일인터넷과', '방송음향영상과', '비서사무행정과', '사회복지과', '산업경영과', '세무회계과', '스포츠지도과',
       '실내디자인과(학부)', '아동문헌정보과', '언어재활과', '유아교육과', '의공융합과', '자동차과', '자동화시스템과',
       '전기과', '전자통신과', '컴퓨터소프트웨어과', '토목환경과', '항공서비스과', '호텔관광과', '호텔외식서비스과',
       '호텔조리과'])

#시각화
plt.scatter(ALL_length,weight)
plt.xlabel('전체학생 과목 평균 점수')
plt.ylabel('전체학과')
plt.grid(True)
plt.show()

#훈련하자잉
X_train, X_test, Y_train, Y_test = \
        train_test_split(ALL_length,weight, test_size=5.0,
                random_state=50)
X_train.shape #(35, 1)
X_train = X_train.reshape(35, 1)
X_train.shape #(35,1) #행렬 2차원 데이터
X_train
X_test = X_test.reshape(-1,1) #배열크기에 -1하면 원소의 개수로 대입
X_test.shape #(15, 1)

#데이터 표준화
A = StandardScaler()
A.fit(X_train) 
X_train_scaled = A.transform(X_train)
X_test_scaled = A.transform(X_test)
#KNeighborsRegressor()
#분석구축
model = KNeighborsRegressor()
model.fit(X_train_scaled, Y_train)

#결과 분석 #테스트 데이터 예측 무게값
model.score(X_train_scaled, Y_train)
model.score(X_test_scaled, Y_test)